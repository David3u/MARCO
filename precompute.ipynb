{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61e268e8-44cd-422f-9c54-7c6c4e9e4a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "from task import Task, Blackboard  # adjust if your Task class is elsewhere\n",
    "from tqdm import tqdm\n",
    "import trainer\n",
    "\n",
    "# Define augmentation types\n",
    "augmentation_types = [\n",
    "    'rotate_90',\n",
    "    'rotate_180',\n",
    "    'rotate_270',\n",
    "    'flip_horizontal',\n",
    "    'flip_vertical',\n",
    "    'value_permutation'\n",
    "]\n",
    "\n",
    "def load_task_data(directory):\n",
    "    \"\"\"Load raw task input/output grids from JSON files\"\"\"\n",
    "    raw_tasks = []\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith(\".json\"):\n",
    "                file_path = os.path.join(root, file)\n",
    "                with open(file_path, \"r\") as f:\n",
    "                    data = json.load(f)\n",
    "                    if \"train\" not in data or \"test\" not in data:\n",
    "                        print(f\"Warning: Invalid task format in {file_path}\")\n",
    "                        continue\n",
    "                    raw_tasks.append({\n",
    "                        \"task_id\": os.path.splitext(file)[0],\n",
    "                        \"train_pairs\": [(pair[\"input\"], pair[\"output\"]) for pair in data[\"train\"]],\n",
    "                        \"test_pairs\": [(pair[\"input\"], pair[\"output\"]) for pair in data[\"test\"]],\n",
    "                    })\n",
    "    return raw_tasks\n",
    "\n",
    "def precompute_and_save_task(task_dict, augmentation_types=None, save_dir=\"precomputed_tasks\"):\n",
    "    \"\"\"\n",
    "    Precompute task data with optional augmentations and save to disk\n",
    "    \n",
    "    Args:\n",
    "        task_dict: Dictionary containing task data (task_id, train_pairs, test_pairs)\n",
    "        augmentation_types: List of augmentation methods to apply (default: None)\n",
    "        save_dir: Directory to save precomputed tasks\n",
    "    \"\"\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    task_id = task_dict[\"task_id\"]\n",
    "    print(f\"Precomputing: {task_id}\")\n",
    "    \n",
    "    # Create the original task\n",
    "    original_task = Task(\n",
    "        task_id=task_id, \n",
    "        train_pairs=task_dict[\"train_pairs\"], \n",
    "        test_pairs=task_dict[\"test_pairs\"]\n",
    "    )\n",
    "    \n",
    "    # Generate augmented versions if augmentation types are provided\n",
    "    all_tasks = [original_task]\n",
    "    if augmentation_types:\n",
    "        augmented_tasks = trainer.generate_augmented_dataset([original_task], augmentation_types)\n",
    "        # Skip the first task as it's the original one already in all_tasks\n",
    "        all_tasks.extend(augmented_tasks[1:])\n",
    "    \n",
    "    # Save each task (original + augmented)\n",
    "    for task in all_tasks:\n",
    "        # Determine the filename (original or augmented)\n",
    "        if task.task_id == task_id:\n",
    "            # Original task\n",
    "            filename = f\"{task_id}.pt\"\n",
    "        else:\n",
    "            # Augmented task\n",
    "            filename = f\"{task.task_id}.pt\"\n",
    "        \n",
    "        # Save the task data\n",
    "        torch.save({\n",
    "            \"task_id\": task.task_id,\n",
    "            \"train_graphs\": task.train_graphs,\n",
    "            \"test_graphs\": task.test_graphs,\n",
    "            \"train_targets\": task.train_targets,\n",
    "            \"test_targets\": task.test_targets\n",
    "        }, os.path.join(save_dir, filename))\n",
    "        \n",
    "    print(f\"Saved precomputed task(s): {task_id} with {len(all_tasks)-1} augmentations\")\n",
    "\n",
    "# Full pipeline function to process a directory of tasks\n",
    "def process_task_directory(input_dir, output_dir=\"precomputed_tasks\", augmentation_types=None):\n",
    "    \"\"\"\n",
    "    Process all tasks in a directory, applying augmentations and saving results\n",
    "    \n",
    "    Args:\n",
    "        input_dir: Directory containing task JSON files\n",
    "        output_dir: Directory to save precomputed tasks\n",
    "        augmentation_types: List of augmentation methods to apply\n",
    "    \"\"\"\n",
    "    print(f\"Processing tasks from {input_dir}\")\n",
    "    print(f\"Using augmentations: {augmentation_types if augmentation_types else 'None'}\")\n",
    "    \n",
    "    # Create output directory\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Load all raw tasks\n",
    "    raw_tasks = load_task_data(input_dir)\n",
    "    print(f\"Found {len(raw_tasks)} tasks to process\")\n",
    "    \n",
    "    # Process each task\n",
    "    for task_dict in raw_tasks:\n",
    "        precompute_and_save_task(\n",
    "            task_dict=task_dict,\n",
    "            augmentation_types=augmentation_types,\n",
    "            save_dir=output_dir\n",
    "        )\n",
    "    \n",
    "    print(f\"Completed processing {len(raw_tasks)} tasks with augmentations\")\n",
    "\n",
    "def load_precomputed_tasks(directory):\n",
    "    \"\"\"Load precomputed tasks from .pt files in directory\"\"\"\n",
    "    tasks = []\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith(\".pt\"):\n",
    "                file_path = os.path.join(root, file)\n",
    "                try:\n",
    "                    task = load_precomputed_task(file_path)\n",
    "                    tasks.append(task)\n",
    "                except Exception as e:\n",
    "                    print(f\"Warning: Failed to load task from {file_path}: {str(e)}\")\n",
    "                    continue\n",
    "    return tasks\n",
    "\n",
    "\n",
    "def load_precomputed_task(path):\n",
    "    \"\"\"Load a single precomputed task from a .pt file\"\"\"\n",
    "    data = torch.load(path, weights_only=False)\n",
    "    task = Task.__new__(Task)  # Bypass __init__\n",
    "    task.task_id = data[\"task_id\"]\n",
    "    task.train_graphs = data[\"train_graphs\"]\n",
    "    task.test_graphs = data[\"test_graphs\"]\n",
    "    task.train_targets = data[\"train_targets\"]\n",
    "    task.test_targets = data[\"test_targets\"]\n",
    "    task.edge_types = [\"edge_index\", \"value_edge_index\", \"region_edge_index\", \n",
    "                       \"contextual_edge_index\", \"alignment_edge_index\"]\n",
    "    task.blackboard = Blackboard()\n",
    "    return task\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c05196b-fe9a-4696-937e-d74676c0b782",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import trainer\n",
    "\n",
    "trainer.precompute_tasks(\n",
    "    input_dir=\"data/evaluation\", \n",
    "    output_dir=\"precomputed_tasks/evaluation_400\",\n",
    "    augmentation_types=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64e0cef-3ab1-4460-92da-09eca7343879",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = traiload_precomputed_task(\"precomputed_tasks/007bbfb7_rotate_90.pt\")\n",
    "print(task.task_id, len(task.train_graphs), len(task.test_graphs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce4c8a5-f179-4c0c-abc2-808c6887c076",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
